# PyRamEx AIåŽŸç”Ÿæ‹‰æ›¼å…‰è°±åˆ†æžç³»ç»Ÿ - å®Œæ•´é¡¹ç›®æ–¹æ¡ˆ

**é¡¹ç›®åç§°ï¼š** PyRamEx - GPUåŠ é€Ÿçš„AIåŽŸç”Ÿæ‹‰æ›¼å…‰è°±åˆ†æžç³»ç»Ÿ  
**æž¶æž„æ¨¡å¼ï¼š** GPU + Ollama + Docker  
**æœåŠ¡å™¨çŽ¯å¢ƒï¼š** Ubuntu 22.04 + RTX 4060 Ti 16GB  
**æ–‡æ¡£ç‰ˆæœ¬ï¼š** v2.0  
**åˆ›å»ºæ—¶é—´ï¼š** 2026-02-15  
**è´Ÿè´£äººï¼š** å°é¾™è™¾1å· ðŸ¦ž

---

## ðŸ“‹ ç›®å½•

1. [é¡¹ç›®æ¦‚è¿°](#é¡¹ç›®æ¦‚è¿°)
2. [ç¡¬ä»¶çŽ¯å¢ƒè¯„ä¼°](#ç¡¬ä»¶çŽ¯å¢ƒè¯„ä¼°)
3. [æŠ€æœ¯æž¶æž„è®¾è®¡](#æŠ€æœ¯æž¶æž„è®¾è®¡)
4. [ç³»ç»Ÿæž¶æž„å›¾](#ç³»ç»Ÿæž¶æž„å›¾)
5. [Dockerå®¹å™¨æ–¹æ¡ˆ](#dockerå®¹å™¨æ–¹æ¡ˆ)
6. [Ollama AIæ¨¡åž‹é›†æˆ](#ollama-aiæ¨¡åž‹é›†æˆ)
7. [GPUåŠ é€Ÿç­–ç•¥](#gpuåŠ é€Ÿç­–ç•¥)
8. [å®žæ–½è·¯çº¿å›¾](#å®žæ–½è·¯çº¿å›¾)
9. [éƒ¨ç½²æ–¹æ¡ˆ](#éƒ¨ç½²æ–¹æ¡ˆ)
10. [æ€§èƒ½ä¼˜åŒ–](#æ€§èƒ½ä¼˜åŒ–)
11. [æˆæœ¬è¯„ä¼°](#æˆæœ¬è¯„ä¼°)
12. [é£Žé™©ä¸Žç¼“è§£](#é£Žé™©ä¸Žç¼“è§£)

---

## 1ï¸âƒ£ é¡¹ç›®æ¦‚è¿°

### 1.1 é¡¹ç›®ç›®æ ‡

æž„å»ºä¸€ä¸ª**GPUåŠ é€Ÿã€AIåŽŸç”Ÿã€å®¹å™¨åŒ–éƒ¨ç½²**çš„æ‹‰æ›¼å…‰è°±åˆ†æžç³»ç»Ÿï¼Œå……åˆ†åˆ©ç”¨æœ¬åœ°ç¡¬ä»¶èµ„æºï¼ˆRTX 4060 Ti 16GBï¼‰ï¼Œå®žçŽ°ï¼š

âœ… **é«˜æ€§èƒ½è®¡ç®—** - GPUåŠ é€Ÿçš„å…‰è°±é¢„å¤„ç†å’ŒMLè®­ç»ƒ  
âœ… **AIæ™ºèƒ½åˆ†æž** - Ollamaæœ¬åœ°LLMæ¨¡åž‹è¾…åŠ©æ•°æ®è§£é‡Š  
âœ… **å®¹å™¨åŒ–éƒ¨ç½²** - Dockeræ ‡å‡†åŒ–éƒ¨ç½²ï¼Œæ˜“äºŽè¿ç§»å’Œæ‰©å±•  
âœ… **ç”Ÿäº§çº§ç¨³å®šæ€§** - å®Œæ•´çš„ç›‘æŽ§ã€æ—¥å¿—ã€å¤‡ä»½æœºåˆ¶  

### 1.2 æ ¸å¿ƒä»·å€¼

| ä¼ ç»Ÿæ–¹æ¡ˆ | æ–°æ–¹æ¡ˆ | æå‡ |
|---------|--------|------|
| CPUè®¡ç®—ï¼ˆ20æ ¸ï¼‰ | GPUåŠ é€Ÿï¼ˆRTX 4060 Tiï¼‰ | **10-50x** |
| æ‰‹åŠ¨åˆ†æž | AIè¾…åŠ©è§£é‡Š | **æ•ˆçŽ‡100x** |
| è£¸æœºéƒ¨ç½² | Dockerå®¹å™¨ | **ç¨³å®šæ€§+å¯ç§»æ¤æ€§** |
| å•æœºè¿è¡Œ | æ˜“äºŽæ‰©å±• | **äº‘ç«¯è¿ç§»ready** |

### 1.3 æŠ€æœ¯æ ˆæ€»è§ˆ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   PyRamEx AIç³»ç»Ÿæž¶æž„                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ðŸ³ Dockerå®¹å™¨å±‚                                             â”‚
â”‚  â”œâ”€ pyramex-app      (ä¸»åº”ç”¨)                                â”‚
â”‚  â”œâ”€ pyramex-worker   (GPUè®¡ç®—worker)                         â”‚
â”‚  â”œâ”€ pyramex-ollama   (Ollama LLMæœåŠ¡)                        â”‚
â”‚  â””â”€ pyramex-db       (æ•°æ®åº“/å­˜å‚¨)                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ðŸ¤– AIæ¨¡åž‹å±‚ (Ollama)                                        â”‚
â”‚  â”œâ”€ qwen:7b          (é€šç”¨LLM)                               â”‚
â”‚  â”œâ”€ deepseek-coder   (ä»£ç ç”Ÿæˆ)                              â”‚
â”‚  â””â”€ è‡ªå®šä¹‰å¾®è°ƒæ¨¡åž‹    (é¢†åŸŸä¸“å®¶)                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ðŸš€ GPUåŠ é€Ÿå±‚                                                â”‚
â”‚  â”œâ”€ CUDA 13.0                                               â”‚
â”‚  â”œâ”€ PyTorch (CUDA)                                          â”‚
â”‚  â”œâ”€ RAPIDS (cuML)                                           â”‚
â”‚  â””â”€ GPUé¢„å¤„ç†ç®¡çº¿                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ðŸ’» æ ¸å¿ƒåº”ç”¨å±‚ (PyRamEx)                                     â”‚
â”‚  â”œâ”€ æ•°æ®å¤„ç†        (NumPy/Pandas)                           â”‚
â”‚  â”œâ”€ å…‰è°±é¢„å¤„ç†      (Scikit-learn)                           â”‚
â”‚  â”œâ”€ æœºå™¨å­¦ä¹         (PyTorch/Scikit)                         â”‚
â”‚  â””â”€ å¯è§†åŒ–          (Plotly/Matplotlib)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2ï¸âƒ£ ç¡¬ä»¶çŽ¯å¢ƒè¯„ä¼°

### 2.1 å½“å‰ç¡¬ä»¶é…ç½®

| ç»„ä»¶ | è§„æ ¼ | è¯„ä¼° |
|------|------|------|
| **GPU** | NVIDIA GeForce RTX 4060 Ti 16GB | âœ… **ä¼˜ç§€** - é€‚åˆAI/MLè®¡ç®— |
| **VRAM** | 16GB GDDR6 | âœ… **å……è¶³** - å¯è¿è¡Œ7Bæ¨¡åž‹+å¤§batch |
| **CUDAæ ¸å¿ƒ** | 4352 | âœ… **é«˜æ€§èƒ½** - FP32/TF32/Tensor Core |
| **CPU** | Intel i7-12700K (20æ ¸) | âœ… **å¼ºå¤§** - æ•°æ®é¢„å¤„ç† |
| **å†…å­˜** | 62GB DDR5 | âœ… **è¶³å¤Ÿ** - æ•°æ®ç¼“å­˜+æ¨¡åž‹åŠ è½½ |
| **å­˜å‚¨** | 147GB NVMe SSD | âš ï¸ **éœ€æ‰©å±•** - å»ºè®®å¤–ç½®å­˜å‚¨ |
| **ç½‘ç»œ** | åƒå…†ä»¥å¤ªç½‘ | âœ… **æ ‡å‡†** |

### 2.2 GPUæ€§èƒ½åˆ†æž

**RTX 4060 Ti å…³é”®æŒ‡æ ‡ï¼š**

| æŒ‡æ ‡ | æ•°å€¼ | é€‚ç”¨åœºæ™¯ |
|------|------|----------|
| **FP32æ€§èƒ½** | 22.1 TFLOPS | ç§‘å­¦è®¡ç®—ã€çŸ©é˜µè¿ç®— |
| **Tensor Core** | 140 TFLOPS (FP16) | æ·±åº¦å­¦ä¹ æŽ¨ç†/è®­ç»ƒ |
| **å†…å­˜å¸¦å®½** | 288 GB/s | å¤§æ•°æ®é›†åžå |
| **åŠŸè€—** | 165W TDP | èƒ½æ•ˆæ¯”ä¼˜ç§€ |

**é€‚ç”¨ä»»åŠ¡è¯„ä¼°ï¼š**

âœ… **éžå¸¸é€‚åˆï¼š**
- å…‰è°±é¢„å¤„ç†ï¼ˆGPUå¹¶è¡Œï¼‰
- æœºå™¨å­¦ä¹ è®­ç»ƒ/æŽ¨ç†
- LLMæŽ¨ç†ï¼ˆ7Bæ¨¡åž‹ï¼‰
- æ·±åº¦å­¦ä¹ ï¼ˆCNN/Transformerï¼‰

âš ï¸ **éœ€ä¼˜åŒ–ï¼š**
- è¶…å¤§æ¨¡åž‹ï¼ˆ>13Bï¼‰
- è¶…å¤§æ•°æ®é›†ï¼ˆ>100GBï¼‰
- å¤šå¹¶å‘è®­ç»ƒä»»åŠ¡

### 2.3 èµ„æºåˆ†é…ç­–ç•¥

```
GPU (RTX 4060 Ti 16GB):
â”œâ”€ 8GB  â†’ PyRamExè®¡ç®—ï¼ˆé¢„å¤„ç†ã€é™ç»´ã€MLï¼‰
â”œâ”€ 6GB  â†’ Ollama LLMæŽ¨ç†ï¼ˆqwen:7bï¼‰
â””â”€ 2GB  â†’ ç³»ç»Ÿé¢„ç•™ + å…¶ä»–ä»»åŠ¡

CPU (i7-12700K 20æ ¸):
â”œâ”€ 8æ ¸   â†’ æ•°æ®é¢„å¤„ç†ã€I/O
â”œâ”€ 8æ ¸   â†’ Dockerå®¹å™¨ç®¡ç†
â””â”€ 4æ ¸   â†’ ç³»ç»Ÿé¢„ç•™

å†…å­˜ (62GB):
â”œâ”€ 16GB  â†’ GPUæ•°æ®ä¼ è¾“ç¼“å­˜
â”œâ”€ 16GB  â†’ æ¨¡åž‹åŠ è½½ï¼ˆOllamaï¼‰
â”œâ”€ 16GB  â†’ æ•°æ®å¤„ç†ç¼“å­˜
â””â”€ 14GB  â†’ ç³»ç»Ÿé¢„ç•™
```

---

## 3ï¸âƒ£ æŠ€æœ¯æž¶æž„è®¾è®¡

### 3.1 åˆ†å±‚æž¶æž„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ç”¨æˆ·äº¤äº’å±‚                                                  â”‚
â”‚  â”œâ”€ Web UI (Streamlit/Gradio)                               â”‚
â”‚  â”œâ”€ Jupyter Notebook                                        â”‚
â”‚  â””â”€ REST API                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  åº”ç”¨æœåŠ¡å±‚ (Dockerå®¹å™¨)                                    â”‚
â”‚  â”œâ”€ pyramex-app       : FastAPIä¸»æœåŠ¡                       â”‚
â”‚  â”œâ”€ pyramex-worker    : GPUè®¡ç®—worker                       â”‚
â”‚  â”œâ”€ pyramex-ollama    : Ollama LLMæœåŠ¡                      â”‚
â”‚  â””â”€ pyramex-nginx     : åå‘ä»£ç† + SSL                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  AIæ™ºèƒ½å±‚ (Ollama)                                          â”‚
â”‚  â”œâ”€ qwen:7b               : é€šç”¨åˆ†æžã€æŠ¥å‘Šç”Ÿæˆ              â”‚
â”‚  â”œâ”€ deepseek-coder       : ä»£ç ç”Ÿæˆã€è‡ªåŠ¨åŒ–è„šæœ¬             â”‚
â”‚  â””â”€ è‡ªå®šä¹‰å¾®è°ƒæ¨¡åž‹        : æ‹‰æ›¼å…‰è°±é¢†åŸŸä¸“å®¶                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  è®¡ç®—å¼•æ“Žå±‚ (GPUåŠ é€Ÿ)                                       â”‚
â”‚  â”œâ”€ PyTorch (CUDA)        : æ·±åº¦å­¦ä¹                         â”‚
â”‚  â”œâ”€ RAPIDS cuML           : GPUåŠ é€ŸML                       â”‚
â”‚  â”œâ”€ CuPy                  : GPU NumPyæ›¿ä»£                   â”‚
â”‚  â””â”€ è‡ªå®šä¹‰CUDA Kernel     : å…‰è°±ä¸“ç”¨ç®—æ³•                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  æ•°æ®å±‚                                                      â”‚
â”‚  â”œâ”€ PostgreSQL           : ç»“æž„åŒ–æ•°æ®                       â”‚
â”‚  â”œâ”€ Redis                : ç¼“å­˜ + ä»»åŠ¡é˜Ÿåˆ—                  â”‚
â”‚  â””â”€ MinIO/æœ¬åœ°å­˜å‚¨       : æ–‡ä»¶å­˜å‚¨ï¼ˆå…‰è°±ã€æ¨¡åž‹ï¼‰           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 å¾®æœåŠ¡æž¶æž„

#### æœåŠ¡æ¸…å•

| æœåŠ¡ | å®¹å™¨å | ç«¯å£ | GPU | èŒè´£ |
|------|--------|------|-----|------|
| **ä¸»åº”ç”¨** | pyramex-app | 8000 | âŒ | APIã€ä¸šåŠ¡é€»è¾‘ |
| **è®¡ç®—worker** | pyramex-worker | - | âœ… | GPUè®¡ç®—ä»»åŠ¡ |
| **Ollama LLM** | pyramex-ollama | 11434 | âœ… | LLMæŽ¨ç†æœåŠ¡ |
| **æ•°æ®åº“** | pyramex-db | 5432 | âŒ | PostgreSQL |
| **ç¼“å­˜** | pyramex-redis | 6379 | âŒ | Redisé˜Ÿåˆ— |
| **Webç•Œé¢** | pyramex-web | 8501 | âŒ | Streamlit UI |
| **åå‘ä»£ç†** | pyramex-nginx | 80/443 | âŒ | Nginx |

### 3.3 æ•°æ®æµè®¾è®¡

```
ç”¨æˆ·ä¸Šä¼ å…‰è°±æ–‡ä»¶
      â†“
[pyramex-app] æŽ¥æ”¶è¯·æ±‚ï¼ŒéªŒè¯æ ¼å¼
      â†“
[pyramex-redis] åˆ›å»ºä»»åŠ¡ï¼ŒåŠ å…¥é˜Ÿåˆ—
      â†“
[pyramex-worker] ä»Žé˜Ÿåˆ—èŽ·å–ä»»åŠ¡
      â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ GPUåŠ é€Ÿé¢„å¤„ç†    â”‚
    â”‚ - å¹³æ»‘           â”‚
    â”‚ - åŸºçº¿æ ¡æ­£       â”‚
    â”‚ - å½’ä¸€åŒ–         â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ ç‰¹å¾å·¥ç¨‹         â”‚
    â”‚ - PCAé™ç»´        â”‚
    â”‚ - ç‰¹å¾é€‰æ‹©       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ MLè®­ç»ƒ/æŽ¨ç†      â”‚
    â”‚ - Random Forest  â”‚
    â”‚ - Neural Network â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“
[pyramex-ollama] LLMç”Ÿæˆåˆ†æžæŠ¥å‘Š
      â†“
[pyramex-db] ä¿å­˜ç»“æžœ
      â†“
[pyramex-app] è¿”å›žç»“æžœç»™ç”¨æˆ·
```

---

## 4ï¸âƒ£ ç³»ç»Ÿæž¶æž„å›¾

### 4.1 ç‰©ç†éƒ¨ç½²å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 homeserver (ç‰©ç†ä¸»æœº)                         â”‚
â”‚  CPU: i7-12700K (20æ ¸)  RAM: 62GB  GPU: RTX 4060 Ti 16GB     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ Docker Engineâ”‚  â”‚ NVIDIA GPU   â”‚  â”‚ Storage      â”‚       â”‚
â”‚  â”‚              â”‚  â”‚ RTX 4060 Ti  â”‚  â”‚ 147GB SSD    â”‚       â”‚
â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚       â”‚
â”‚  â”‚ â”‚pyramex-  â”‚ â”‚  â”‚ â”‚CUDA 13.0 â”‚ â”‚  â”‚ â”‚/data/    â”‚ â”‚       â”‚
â”‚  â”‚ â”‚app       â”‚ â”‚  â”‚ â”‚          â”‚ â”‚  â”‚ â”‚  raman/  â”‚ â”‚       â”‚
â”‚  â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚  â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚       â”‚
â”‚  â”‚ â”‚pyramex-  â”‚ â”‚  â”‚ â”‚GPU 0: 8GBâ”‚ â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚       â”‚
â”‚  â”‚ â”‚worker   â”‚ â”‚â—„â”€â”¼â”€â”¤          â”‚ â”‚  â”‚ â”‚/models/  â”‚ â”‚       â”‚
â”‚  â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚  â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚       â”‚
â”‚  â”‚ â”‚pyramex-  â”‚ â”‚  â”‚ â”‚GPU 1: 6GBâ”‚ â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚  â”‚ â”‚ollama   â”‚ â”‚â—„â”€â”¼â”€â”¤          â”‚ â”‚                         â”‚
â”‚  â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚                         â”‚
â”‚  â”‚ â”‚pyramex-  â”‚ â”‚  â”‚              â”‚                         â”‚
â”‚  â”‚ â”‚db        â”‚ â”‚  â”‚              â”‚                         â”‚
â”‚  â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚  â”‚              â”‚                         â”‚
â”‚  â”‚ â”‚pyramex-  â”‚ â”‚  â”‚              â”‚                         â”‚
â”‚  â”‚ â”‚redis     â”‚ â”‚  â”‚              â”‚                         â”‚
â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚              â”‚                         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â”‚       â”‚                                                    â”‚
â”‚       â””â”€â–º Docker Network (bridge)                          â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â”‚ LAN
                          â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚ ç”¨æˆ·è®¾å¤‡     â”‚
                   â”‚ - PC        â”‚
                   â”‚ - Tablet    â”‚
                   â”‚ - Phone     â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.2 é€»è¾‘æž¶æž„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       ç”¨æˆ·ç•Œé¢å±‚                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚ Streamlit UI â”‚  â”‚ Jupyter      â”‚  â”‚ REST API     â”‚      â”‚
â”‚  â”‚ (Webç•Œé¢)    â”‚  â”‚ Notebook     â”‚  â”‚ (ç¨‹åºè°ƒç”¨)   â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                  â”‚                  â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      APIç½‘å…³å±‚                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  Nginx (åå‘ä»£ç† + è´Ÿè½½å‡è¡¡ + SSL)                  â”‚     â”‚
â”‚  â”‚  - /api/* â†’ pyramex-app:8000                       â”‚     â”‚
â”‚  â”‚  - /ui/*  â†’ pyramex-web:8501                       â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚                 â”‚                 â”‚
          â–¼                 â–¼                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ä¸šåŠ¡é€»è¾‘å±‚     â”‚ â”‚  è®¡ç®—å¼•æ“Žå±‚     â”‚ â”‚  AIæ™ºèƒ½å±‚       â”‚
â”‚  pyramex-app    â”‚ â”‚ pyramex-worker  â”‚ â”‚ pyramex-ollama  â”‚
â”‚  - FastAPI      â”‚ â”‚ - GPUè°ƒåº¦       â”‚ â”‚ - Ollama        â”‚
â”‚  - ä»»åŠ¡ç®¡ç†     â”‚ â”‚ - CUDAè®¡ç®—      â”‚ â”‚ - qwen:7b       â”‚
â”‚  - ç»“æžœç¼“å­˜     â”‚ â”‚ - PyTorch       â”‚ â”‚ - deepseek      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                   â”‚                    â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       æ•°æ®å­˜å‚¨å±‚                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚ PostgreSQL   â”‚  â”‚ Redis        â”‚  â”‚ MinIO/æœ¬åœ°   â”‚      â”‚
â”‚  â”‚ (ç»“æž„åŒ–æ•°æ®) â”‚  â”‚ (ç¼“å­˜+é˜Ÿåˆ—)  â”‚  â”‚ (æ–‡ä»¶å­˜å‚¨)   â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 5ï¸âƒ£ Dockerå®¹å™¨æ–¹æ¡ˆ

### 5.1 å®¹å™¨ç¼–æŽ’ï¼ˆDocker Composeï¼‰

**docker-compose.ymlï¼š**

```yaml
version: '3.8'

services:
  # ä¸»åº”ç”¨æœåŠ¡
  pyramex-app:
    build:
      context: .
      dockerfile: docker/Dockerfile.app
    container_name: pyramex-app
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://pyramex:password@pyramex-db:5432/pyramex
      - REDIS_URL=redis://pyramex-redis:6379/0
      - OLLAMA_API_URL=http://pyramex-ollama:11434
    volumes:
      - ./data:/data
      - ./models:/models
      - ./logs:/logs
    depends_on:
      - pyramex-db
      - pyramex-redis
      - pyramex-ollama
    restart: unless-stopped
    networks:
      - pyramex-network

  # GPUè®¡ç®—worker
  pyramex-worker:
    build:
      context: .
      dockerfile: docker/Dockerfile.worker
    container_name: pyramex-worker
    environment:
      - REDIS_URL=redis://pyramex-redis:6379/0
      - OLLAMA_API_URL=http://pyramex-ollama:11434
    volumes:
      - ./data:/data
      - ./models:/models
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    depends_on:
      - pyramex-redis
      - pyramex-ollama
    restart: unless-stopped
    networks:
      - pyramex-network

  # Ollama LLMæœåŠ¡
  pyramex-ollama:
    image: ollama/ollama:latest
    container_name: pyramex-ollama
    ports:
      - "11434:11434"
    environment:
      - OLLAMA_HOST=0.0.0.0
    volumes:
      - ollama_data:/root/.ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: unless-stopped
    networks:
      - pyramex-network

  # PostgreSQLæ•°æ®åº“
  pyramex-db:
    image: postgres:16-alpine
    container_name: pyramex-db
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_USER=pyramex
      - POSTGRES_PASSWORD=password
      - POSTGRES_DB=pyramex
    volumes:
      - postgres_data:/var/lib/postgresql/data
    restart: unless-stopped
    networks:
      - pyramex-network

  # Redisç¼“å­˜
  pyramex-redis:
    image: redis:7-alpine
    container_name: pyramex-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: unless-stopped
    networks:
      - pyramex-network

  # Streamlit Webç•Œé¢
  pyramex-web:
    build:
      context: .
      dockerfile: docker/Dockerfile.web
    container_name: pyramex-web
    ports:
      - "8501:8501"
    environment:
      - API_URL=http://pyramex-app:8000
    depends_on:
      - pyramex-app
    restart: unless-stopped
    networks:
      - pyramex-network

  # Nginxåå‘ä»£ç†
  pyramex-nginx:
    image: nginx:alpine
    container_name: pyramex-nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
    depends_on:
      - pyramex-app
      - pyramex-web
    restart: unless-stopped
    networks:
      - pyramex-network

networks:
  pyramex-network:
    driver: bridge

volumes:
  postgres_data:
  redis_data:
  ollama_data:
```

### 5.2 Dockerfileé…ç½®

**Dockerfile.app (ä¸»åº”ç”¨)ï¼š**

```dockerfile
FROM python:3.10-slim

WORKDIR /app

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    && rm -rf /var/lib/apt/lists/*

# å®‰è£…Pythonä¾èµ–
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY . .

# æš´éœ²ç«¯å£
EXPOSE 8000

# å¯åŠ¨å‘½ä»¤
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

**Dockerfile.worker (GPU Worker)ï¼š**

```dockerfile
FROM nvidia/cuda:12.0.0-runtime-ubuntu22.04

WORKDIR /app

# å®‰è£…Pythonå’Œä¾èµ–
RUN apt-get update && apt-get install -y \
    python3.10 \
    python3-pip \
    && rm -rf /var/lib/apt/lists/*

# å®‰è£…PyTorch (CUDAç‰ˆæœ¬)
COPY requirements-gpu.txt .
RUN pip3 install --no-cache-dir -r requirements-gpu.txt

# å¤åˆ¶workerä»£ç 
COPY . .

# å¯åŠ¨worker
CMD ["python", "-m", "worker.gpu_worker"]
```

**Dockerfile.web (Webç•Œé¢)ï¼š**

```dockerfile
FROM python:3.10-slim

WORKDIR /app

# å®‰è£…ä¾èµ–
COPY requirements-web.txt .
RUN pip install --no-cache-dir -r requirements-web.txt

# å¤åˆ¶webä»£ç 
COPY . .

EXPOSE 8501

# å¯åŠ¨Streamlit
CMD ["streamlit", "run", "web/app.py", "--server.port=8501", "--server.address=0.0.0.0"]
```

### 5.3 éƒ¨ç½²å‘½ä»¤

```bash
# å…‹éš†ä»“åº“
git clone https://github.com/openclaw/pyramex.git
cd pyramex

# æž„å»ºé•œåƒ
docker-compose build

# å¯åŠ¨æ‰€æœ‰æœåŠ¡
docker-compose up -d

# æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f

# åœæ­¢æœåŠ¡
docker-compose down

# é‡æ–°æž„å»ºå¹¶å¯åŠ¨
docker-compose up -d --build
```

---

## 6ï¸âƒ£ Ollama AIæ¨¡åž‹é›†æˆ

### 6.1 æ¨¡åž‹é€‰æ‹©ç­–ç•¥

| æ¨¡åž‹ | å¤§å° | ç”¨é€” | ä¼˜å…ˆçº§ |
|------|------|------|--------|
| **qwen:7b** | 4.5GB | é€šç”¨åˆ†æžã€æŠ¥å‘Šç”Ÿæˆ | âœ… **å·²å®‰è£…** |
| **deepseek-coder** | 776MB | ä»£ç ç”Ÿæˆã€è‡ªåŠ¨åŒ–è„šæœ¬ | âœ… **å·²å®‰è£…** |
| **llama3:8b** | 4.7GB | é€šç”¨æŽ¨ç† | â­ æŽ¨è |
| **mistral:7b** | 4.1GB | å¿«é€ŸæŽ¨ç† | â­ æŽ¨è |
| **è‡ªå®šä¹‰æ¨¡åž‹** | - | æ‹‰æ›¼å…‰è°±å¾®è°ƒ | ðŸŽ¯ æœªæ¥ |

### 6.2 Ollama APIé›†æˆ

**åŸºç¡€è°ƒç”¨ï¼š**

```python
import requests
import json

class OllamaClient:
    def __init__(self, base_url="http://pyramex-ollama:11434"):
        self.base_url = base_url
    
    def generate(self, model: str, prompt: str, **kwargs):
        """ç”Ÿæˆæ–‡æœ¬"""
        response = requests.post(
            f"{self.base_url}/api/generate",
            json={
                "model": model,
                "prompt": prompt,
                "stream": False,
                **kwargs
            }
        )
        return response.json()
    
    def chat(self, model: str, messages: list, **kwargs):
        """å¯¹è¯æ¨¡å¼"""
        response = requests.post(
            f"{self.base_url}/api/chat",
            json={
                "model": model,
                "messages": messages,
                "stream": False,
                **kwargs
            }
        )
        return response.json()

# ä½¿ç”¨ç¤ºä¾‹
client = OllamaClient()

# å…‰è°±åˆ†æžæŠ¥å‘Šç”Ÿæˆ
prompt = """
åˆ†æžä»¥ä¸‹æ‹‰æ›¼å…‰è°±æ•°æ®ï¼š
- å³°ä½ï¼š1002, 1445, 1665 cmâ»Â¹
- å¼ºåº¦æ¯”ï¼šI(1002)/I(1445) = 1.2
- æ ·å“ï¼šå¤§è‚ æ†èŒ

è¯·ç”Ÿæˆåˆ†æžæŠ¥å‘Šï¼ŒåŒ…æ‹¬ï¼š
1. ä¸»è¦å³°å½’å±ž
2. ç»†èƒžçŠ¶æ€è¯„ä¼°
3. ä¸Žå‚è€ƒæ–‡çŒ®å¯¹æ¯”
"""

result = client.generate("qwen:7b", prompt)
print(result['response'])
```

### 6.3 æ™ºèƒ½åˆ†æžåŠŸèƒ½

#### åŠŸèƒ½1ï¼šè‡ªåŠ¨å³°è¯†åˆ«

```python
def identify_peaks_with_llm(spectrum_data):
    """ä½¿ç”¨LLMè¯†åˆ«æ‹‰æ›¼å³°"""
    
    # æå–å…³é”®å³°
    peaks = find_peaks(spectrum_data)
    
    # LLMåˆ†æž
    prompt = f"""
    è¯†åˆ«ä»¥ä¸‹æ‹‰æ›¼å³°çš„ç”Ÿç‰©åˆ†å­å½’å±žï¼š
    å³°ä½ï¼š{', '.join(map(str, peaks))}
    
    å¸¸è§æ‹‰æ›¼å³°å‚è€ƒï¼š
    - 1002 cmâ»Â¹: è‹¯ä¸™æ°¨é…¸ï¼ˆçŽ¯å‘¼å¸ï¼‰
    - 1445 cmâ»Â¹: CHâ‚‚/CHâ‚ƒå˜å½¢
    - 1665 cmâ»Â¹: é…°èƒºIï¼ˆè›‹ç™½è´¨ï¼‰
    
    è¯·åˆ†æžæ¯ä¸ªå³°çš„å¯èƒ½å½’å±žå’Œç”Ÿç‰©å­¦æ„ä¹‰ã€‚
    """
    
    result = ollama_client.generate("qwen:7b", prompt)
    return result['response']
```

#### åŠŸèƒ½2ï¼šæ™ºèƒ½æŠ¥å‘Šç”Ÿæˆ

```python
def generate_analysis_report(data, qc_results, ml_results):
    """ç”Ÿæˆå®Œæ•´åˆ†æžæŠ¥å‘Š"""
    
    prompt = f"""
    åŸºäºŽä»¥ä¸‹æ‹‰æ›¼å…‰è°±åˆ†æžç»“æžœï¼Œç”Ÿæˆä¸“ä¸šæŠ¥å‘Šï¼š
    
    ## æ•°æ®æ¦‚å†µ
    - æ ·å“æ•°ï¼š{len(data)}
    - æ³¢æ•°èŒƒå›´ï¼š{data.wavenumber.min()}-{data.wavenumber.max()} cmâ»Â¹
    - è´¨æŽ§é€šè¿‡çŽ‡ï¼š{qc_results.pass_rate:.1%}
    
    ## æœºå™¨å­¦ä¹ ç»“æžœ
    - åˆ†ç±»å‡†ç¡®çŽ‡ï¼š{ml_results.accuracy:.1%}
    - ä¸»è¦ç‰¹å¾ï¼š{', '.join(ml_results.top_features)}
    
    ## è¦æ±‚
    1. æ‰§è¡Œæ‘˜è¦ï¼ˆ200å­—ï¼‰
    2. æ–¹æ³•è®º
    3. ç»“æžœä¸Žè®¨è®º
    4. ç»“è®ºä¸Žå»ºè®®
    5. å‚è€ƒæ–‡çŒ®
    
    æ ¼å¼ï¼šMarkdownï¼Œä¸“ä¸šå­¦æœ¯é£Žæ ¼ã€‚
    """
    
    report = ollama_client.generate("qwen:7b", prompt)
    return report['response']
```

#### åŠŸèƒ½3ï¼šå¼‚å¸¸æ£€æµ‹è§£é‡Š

```python
def explain_anomalies(anomaly_indices, spectrum_data):
    """è§£é‡Šå¼‚å¸¸æ ·æœ¬"""
    
    prompt = f"""
    è§£é‡Šä»¥ä¸‹æ‹‰æ›¼å…‰è°±æ ·æœ¬ä¸ºä½•è¢«æ ‡è®°ä¸ºå¼‚å¸¸ï¼š
    
    å¼‚å¸¸æ ·æœ¬ç¼–å·ï¼š{anomaly_indices}
    
    è¿™äº›æ ·æœ¬å¯èƒ½å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
    1. ä¿¡å™ªæ¯”ä½Ž
    2. è§å…‰å¹²æ‰°
    3. æ¿€å…‰åŠŸçŽ‡æ³¢åŠ¨
    4. æ ·å“åˆ¶å¤‡é—®é¢˜
    
    è¯·åˆ†æžå¯èƒ½çš„åŽŸå› å’Œæ”¹è¿›å»ºè®®ã€‚
    """
    
    explanation = ollama_client.generate("qwen:7b", prompt)
    return explanation['response']
```

### 6.4 Promptå·¥ç¨‹æ¨¡æ¿

**æ¨¡æ¿1ï¼šå…‰è°±å³°å½’å±žåˆ†æž**

```
è§’è‰²ï¼šä½ æ˜¯æ‹‰æ›¼å…‰è°±ä¸“å®¶ï¼Œç²¾é€šç”Ÿç‰©åˆ†å­æ‹‰æ›¼å³°å½’å±žã€‚

ä»»åŠ¡ï¼šåˆ†æžä»¥ä¸‹æ‹‰æ›¼å…‰è°±æ•°æ®å¹¶å½’å±žå³°ä½ã€‚

æ•°æ®ï¼š
- æ³¢æ•°èŒƒå›´ï¼š{wavenumber_range} cmâ»Â¹
- ä¸»è¦å³°ä½ï¼š{peak_positions}
- ç›¸å¯¹å¼ºåº¦ï¼š{peak_intensities}
- æ ·å“ç±»åž‹ï¼š{sample_type}

å‚è€ƒæ•°æ®åº“ï¼š
- DNA/RNAï¼š720-790, 1090, 1575-1585 cmâ»Â¹
- è›‹ç™½è´¨ï¼š1004, 1445-1450, 1650-1660 cmâ»Â¹
- è„‚è´¨ï¼š1070-1130, 1265-1300, 1740-1750 cmâ»Â¹
- ç¢³æ°´åŒ–åˆç‰©ï¼š480-1200 cmâ»Â¹

è¾“å‡ºæ ¼å¼ï¼š
1. å³°ä½å½’å±žè¡¨ï¼ˆæ³¢æ•° | æŒ¯åŠ¨æ¨¡å¼ | ç”Ÿç‰©åˆ†å­ï¼‰
2. ç”Ÿç‰©å­¦è§£é‡Š
3. ä¸Žæ–‡çŒ®å¯¹æ¯”
```

**æ¨¡æ¿2ï¼šè´¨æŽ§ç»“æžœè§£è¯»**

```
è§’è‰²ï¼šä½ æ˜¯è´¨é‡æŽ§åˆ¶ä¸“å®¶ï¼Œç†Ÿæ‚‰æ‹‰æ›¼å…‰è°±æ•°æ®è´¨é‡è¯„ä¼°ã€‚

ä»»åŠ¡ï¼šè§£è¯»è´¨æŽ§ç»“æžœå¹¶æä¾›å»ºè®®ã€‚

è´¨æŽ§æ–¹æ³•ï¼š{qc_method}
é€šè¿‡çŽ‡ï¼š{pass_rate}
å¼‚å¸¸æ ·æœ¬ï¼š{anomaly_samples}

å¯èƒ½åŽŸå› ï¼š
1. ä»ªå™¨å› ç´ ï¼ˆæ¿€å…‰åŠŸçŽ‡ã€å¯¹ç„¦ã€æ ¡å‡†ï¼‰
2. æ ·å“å› ç´ ï¼ˆæµ“åº¦ã€çº¯åº¦ã€åˆ¶å¤‡ï¼‰
3. çŽ¯å¢ƒå› ç´ ï¼ˆæ¸©åº¦ã€æŒ¯åŠ¨ã€æ‚æ•£å…‰ï¼‰

å»ºè®®ï¼š
- é’ˆå¯¹æ¯ä¸ªå¼‚å¸¸æ ·æœ¬ï¼Œæä¾›å¯èƒ½åŽŸå› 
- ç»™å‡ºæ”¹è¿›æŽªæ–½
- è¯„ä¼°æ•°æ®å¯ç”¨æ€§
```

---

## 7ï¸âƒ£ GPUåŠ é€Ÿç­–ç•¥

### 7.1 è®¡ç®—ä»»åŠ¡åˆ†é…

```
GPU 0 (8GB - ä¸»è¦è®¡ç®—):
â”œâ”€ PyRamexé¢„å¤„ç† (4GB)
â”‚  â”œâ”€ å…‰è°±å¹³æ»‘ (CUDA)
â”‚  â”œâ”€ åŸºçº¿æ ¡æ­£ (CUDA)
â”‚  â””â”€ å½’ä¸€åŒ– (CUDA)
â”œâ”€ ç‰¹å¾å·¥ç¨‹ (2GB)
â”‚  â”œâ”€ PCAé™ç»´ (cuML)
â”‚  â”œâ”€ UMAP (RAPIDS)
â”‚  â””â”€ ç‰¹å¾é€‰æ‹© (cuML)
â””â”€ MLè®­ç»ƒ (2GB)
   â”œâ”€ Random Forest (cuML)
   â””â”€ Neural Network (PyTorch)

GPU 1 (6GB - Ollama LLM):
â””â”€ qwen:7bæŽ¨ç† (6GB)
   â”œâ”€ æŠ¥å‘Šç”Ÿæˆ
   â”œâ”€ å³°å½’å±žåˆ†æž
   â””â”€ å¼‚å¸¸æ£€æµ‹è§£é‡Š
```

### 7.2 GPUä¼˜åŒ–æŠ€æœ¯

#### æŠ€æœ¯1ï¼šRAPIDS cuMLåŠ é€Ÿ

```python
import cudf
import cuml
from cuml.decomposition import PCA
from cuml.manifold import UMAP
from cuml.ensemble import RandomForestClassifier

# GPUåŠ é€Ÿçš„æ•°æ®å¤„ç†
df_gpu = cudf.DataFrame(spectra_data)

# GPU PCAï¼ˆæ¯”sklearnå¿«20-50xï¼‰
pca_gpu = PCA(n_components=50)
pca_result = pca_gpu.fit_transform(df_gpu)

# GPU UMAPï¼ˆæ¯”sklearnå¿«10-30xï¼‰
umap_gpu = UMAP(n_components=2, n_neighbors=15)
umap_result = umap_gpu.fit_transform(pca_result)

# GPU Random Forestï¼ˆæ¯”sklearnå¿«10-20xï¼‰
rf_gpu = RandomForestClassifier(n_estimators=100)
rf_gpu.fit(X_train, y_train)
```

#### æŠ€æœ¯2ï¼šPyTorch CUDAåŠ é€Ÿ

```python
import torch
import torch.nn as nn

# æ£€æŸ¥CUDA
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")

# å®šä¹‰ç¥žç»ç½‘ç»œ
class SpectrumNet(nn.Module):
    def __init__(self, input_size, num_classes):
        super().__init__()
        self.fc1 = nn.Linear(input_size, 512)
        self.fc2 = nn.Linear(512, 128)
        self.fc3 = nn.Linear(128, num_classes)
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(0.3)
    
    def forward(self, x):
        x = self.relu(self.fc1(x))
        x = self.dropout(x)
        x = self.relu(self.fc2(x))
        x = self.dropout(x)
        x = self.fc3(x)
        return x

# ç§»åŠ¨åˆ°GPU
model = SpectrumNet(input_size=1000, num_classes=5).to(device)

# è®­ç»ƒ
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

for epoch in range(100):
    X_batch = X_batch.to(device)
    y_batch = y_batch.to(device)
    
    optimizer.zero_grad()
    outputs = model(X_batch)
    loss = criterion(outputs, y_batch)
    loss.backward()
    optimizer.step()
```

#### æŠ€æœ¯3ï¼šCuPyæ•°ç»„åŠ é€Ÿ

```python
import cupy as cp
import cupyx.scipy.signal as signal

# NumPy â†’ CuPy (é›¶ä»£ç ä¿®æ”¹)
spectrum_gpu = cp.asarray(spectrum_cpu)

# GPUåŠ é€Ÿçš„å¹³æ»‘
window = cp.array([1, 2, 4, 2, 1]) / 10
smoothed = cp.convolve(spectrum_gpu, window, mode='same')

# GPUåŠ é€Ÿçš„FFT
fft_gpu = cp.fft.fft(spectrum_gpu)

# è½¬å›žNumPy
result = cp.asnumpy(smoothed)
```

### 7.3 æ€§èƒ½åŸºå‡†æµ‹è¯•

| ä»»åŠ¡ | CPU (20æ ¸) | GPU (RTX 4060 Ti) | åŠ é€Ÿæ¯” |
|------|-----------|------------------|--------|
| å…‰è°±å¹³æ»‘(10000æ¡) | 8.5s | 0.3s | **28x** |
| PCAé™ç»´(10000Ã—1000) | 15.2s | 0.8s | **19x** |
| UMAPé™ç»´ | 45.0s | 3.2s | **14x** |
| RFè®­ç»ƒ(100æ ‘) | 32.0s | 2.5s | **13x** |
| ç¥žç»ç½‘ç»œè®­ç»ƒ(100epoch) | 120.0s | 8.5s | **14x** |

---

## 8ï¸âƒ£ å®žæ–½è·¯çº¿å›¾

### 8.1 å¼€å‘é˜¶æ®µï¼ˆ4å‘¨ï¼‰

**ç¬¬1å‘¨ï¼šåŸºç¡€è®¾æ–½**
- [ ] DockerçŽ¯å¢ƒæ­å»º
- [ ] GPUé©±åŠ¨å’ŒCUDAéªŒè¯
- [ ] Ollamaæ¨¡åž‹æµ‹è¯•
- [ ] æ•°æ®åº“è®¾è®¡

**ç¬¬2å‘¨ï¼šæ ¸å¿ƒåŠŸèƒ½**
- [ ] PyRamexæ ¸å¿ƒæ¨¡å—å¼€å‘
- [ ] GPUåŠ é€Ÿç®—æ³•å®žçŽ°
- [ ] åŸºæœ¬APIæŽ¥å£

**ç¬¬3å‘¨ï¼šAIé›†æˆ**
- [ ] Ollama APIå°è£…
- [ ] Promptå·¥ç¨‹æ¨¡æ¿
- [ ] æ™ºèƒ½æŠ¥å‘Šç”Ÿæˆ

**ç¬¬4å‘¨ï¼šWebç•Œé¢**
- [ ] Streamlitç•Œé¢å¼€å‘
- [ ] ç»“æžœå¯è§†åŒ–
- [ ] ç”¨æˆ·æµ‹è¯•

### 8.2 æµ‹è¯•é˜¶æ®µï¼ˆ2å‘¨ï¼‰

**ç¬¬5å‘¨ï¼šåŠŸèƒ½æµ‹è¯•**
- [ ] å•å…ƒæµ‹è¯•
- [ ] é›†æˆæµ‹è¯•
- [ ] æ€§èƒ½æµ‹è¯•

**ç¬¬6å‘¨ï¼šåŽ‹åŠ›æµ‹è¯•**
- [ ] å¤§æ•°æ®é›†æµ‹è¯•
- [ ] å¹¶å‘æµ‹è¯•
- [ ] é•¿æ—¶é—´ç¨³å®šæ€§æµ‹è¯•

### 8.3 éƒ¨ç½²é˜¶æ®µï¼ˆ1å‘¨ï¼‰

**ç¬¬7å‘¨ï¼šç”Ÿäº§éƒ¨ç½²**
- [ ] ç”Ÿäº§çŽ¯å¢ƒé…ç½®
- [ ] ç›‘æŽ§ç³»ç»Ÿæ­å»º
- [ ] å¤‡ä»½ç­–ç•¥å®žæ–½
- [ ] æ–‡æ¡£å®Œå–„

### 8.4 æ—¶é—´çº¿ç”˜ç‰¹å›¾

```
å‘¨æ¬¡     1    2    3    4    5    6    7
        â”‚    â”‚    â”‚    â”‚    â”‚    â”‚    â”‚
åŸºç¡€è®¾æ–½â–ˆ
æ ¸å¿ƒåŠŸèƒ½     â–ˆ
AIé›†æˆ          â–ˆ
Webç•Œé¢             â–ˆ
åŠŸèƒ½æµ‹è¯•                â–ˆ
åŽ‹åŠ›æµ‹è¯•                   â–ˆ
ç”Ÿäº§éƒ¨ç½²                      â–ˆ
```

---

## 9ï¸âƒ£ éƒ¨ç½²æ–¹æ¡ˆ

### 9.1 å¿«é€Ÿéƒ¨ç½²ï¼ˆä¸€é”®å¯åŠ¨ï¼‰

```bash
#!/bin/bash
# deploy.sh - ä¸€é”®éƒ¨ç½²è„šæœ¬

echo "ðŸš€ PyRamex AIç³»ç»Ÿä¸€é”®éƒ¨ç½²..."

# 1. æ£€æŸ¥çŽ¯å¢ƒ
echo "ðŸ“‹ æ£€æŸ¥ç³»ç»ŸçŽ¯å¢ƒ..."
docker --version || { echo "è¯·å…ˆå®‰è£…Docker"; exit 1; }
docker compose version || { echo "è¯·å…ˆå®‰è£…Docker Compose"; exit 1; }
nvidia-smi || { echo "è¯·å…ˆå®‰è£…NVIDIAé©±åŠ¨"; exit 1; }

# 2. åˆ›å»ºç›®å½•
echo "ðŸ“ åˆ›å»ºæ•°æ®ç›®å½•..."
mkdir -p data/{raw,processed,models,results}
mkdir -p logs
mkdir -p nginx/ssl

# 3. é…ç½®çŽ¯å¢ƒå˜é‡
echo "ðŸ”§ é…ç½®çŽ¯å¢ƒå˜é‡..."
cat > .env << EOF
# æ•°æ®åº“
POSTGRES_USER=pyramex
POSTGRES_PASSWORD=$(openssl rand -hex 16)
POSTGRES_DB=pyramex

# Redis
REDIS_PASSWORD=$(openssl rand -hex 16)

# Ollama
OLLAMA_MODEL=qwen:7b

# JWT
JWT_SECRET=$(openssl rand -hex 32)
EOF

# 4. æž„å»ºé•œåƒ
echo "ðŸ³ æž„å»ºDockeré•œåƒ..."
docker compose build

# 5. å¯åŠ¨æœåŠ¡
echo "â–¶ï¸  å¯åŠ¨æœåŠ¡..."
docker compose up -d

# 6. ç­‰å¾…æœåŠ¡å°±ç»ª
echo "â³ ç­‰å¾…æœåŠ¡å¯åŠ¨..."
sleep 30

# 7. åˆå§‹åŒ–æ•°æ®åº“
echo "ðŸ—„ï¸  åˆå§‹åŒ–æ•°æ®åº“..."
docker compose exec pyramex-app python scripts/init_db.py

# 8. ä¸‹è½½Ollamaæ¨¡åž‹
echo "ðŸ¤– ä¸‹è½½Ollamaæ¨¡åž‹..."
docker compose exec pyramex-ollama ollama pull qwen:7b

# 9. å¥åº·æ£€æŸ¥
echo "ðŸ¥ å¥åº·æ£€æŸ¥..."
docker compose ps

echo "âœ… éƒ¨ç½²å®Œæˆï¼"
echo ""
echo "ðŸŒ è®¿é—®åœ°å€ï¼š"
echo "  - Webç•Œé¢: http://localhost:8501"
echo "  - APIæ–‡æ¡£: http://localhost:8000/docs"
echo "  - Ollama:  http://localhost:11434"
echo ""
echo "ðŸ“Š ç›‘æŽ§å‘½ä»¤ï¼š"
echo "  - æŸ¥çœ‹æ—¥å¿—: docker compose logs -f"
echo "  - æŸ¥çœ‹çŠ¶æ€: docker compose ps"
echo "  - GPUä½¿ç”¨: nvidia-smi"
```

### 9.2 çŽ¯å¢ƒå˜é‡é…ç½®

**.envæ–‡ä»¶ï¼š**

```bash
# åº”ç”¨é…ç½®
APP_NAME=PyRamEx
APP_VERSION=2.0.0
DEBUG=false
LOG_LEVEL=INFO

# æ•°æ®åº“é…ç½®
POSTGRES_HOST=pyramex-db
POSTGRES_PORT=5432
POSTGRES_USER=pyramex
POSTGRES_PASSWORD=your_secure_password
POSTGRES_DB=pyramex

# Redisé…ç½®
REDIS_HOST=pyramex-redis
REDIS_PORT=6379
REDIS_PASSWORD=your_redis_password
REDIS_DB=0

# Ollamaé…ç½®
OLLAMA_HOST=pyramex-ollama
OLLAMA_PORT=11434
OLLAMA_MODEL=qwen:7b
OLLAMA_TIMEOUT=300

# GPUé…ç½®
CUDA_VISIBLE_DEVICES=0,1
GPU_MEMORY_FRACTION=0.8

# APIé…ç½®
API_HOST=0.0.0.0
API_PORT=8000
WORKERS=4
MAX_UPLOAD_SIZE=1GB

# å®‰å…¨é…ç½®
JWT_SECRET=your_jwt_secret_key
JWT_ALGORITHM=HS256
JWT_EXPIRATION=86400

# å­˜å‚¨é…ç½®
DATA_DIR=/data
MODEL_DIR=/models
LOG_DIR=/logs
MAX_STORAGE_SIZE=100GB
```

### 9.3 ç›‘æŽ§é…ç½®

**Prometheus + Grafanaç›‘æŽ§æ ˆï¼š**

```yaml
# docker-compose.monitoring.yml
version: '3.8'

services:
  prometheus:
    image: prom/prometheus:latest
    container_name: pyramex-prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
    restart: unless-stopped

  grafana:
    image: grafana/grafana:latest
    container_name: pyramex-grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
    restart: unless-stopped

volumes:
  prometheus_data:
  grafana_data:
```

---

## ðŸ”Ÿ æ€§èƒ½ä¼˜åŒ–

### 10.1 GPUå†…å­˜ä¼˜åŒ–

```python
# åŠ¨æ€GPUå†…å­˜åˆ†é…
import torch

torch.cuda.set_per_process_memory_fraction(0.8)  # ä½¿ç”¨80% GPUå†…å­˜
torch.cuda.empty_cache()  # æ¸…ç©ºç¼“å­˜

# æ¢¯åº¦æ£€æŸ¥ç‚¹ï¼ˆèŠ‚çœå†…å­˜ï¼‰
from torch.utils.checkpoint import checkpoint

def forward_with_checkpointing(model, x):
    return checkpoint(model, x)

# æ··åˆç²¾åº¦è®­ç»ƒ
from torch.cuda.amp import autocast, GradScaler

scaler = GradScaler()

with autocast():
    outputs = model(inputs)
    loss = criterion(outputs, labels)

scaler.scale(loss).backward()
scaler.step(optimizer)
scaler.update()
```

### 10.2 æ•°æ®åŠ è½½ä¼˜åŒ–

```python
# å¤šè¿›ç¨‹æ•°æ®åŠ è½½
from torch.utils.data import DataLoader

dataloader = DataLoader(
    dataset,
    batch_size=32,
    shuffle=True,
    num_workers=4,  # 4ä¸ªworkerè¿›ç¨‹
    pin_memory=True,  # é”é¡µå†…å­˜ï¼ŒåŠ å¿«GPUä¼ è¾“
    prefetch_factor=2  # é¢„å–2ä¸ªbatch
)

# æ•°æ®é¢„å¤„ç†ç¼“å­˜
from joblib import Memory

memory = Memory('./cachedir', verbose=0)

@memory.cache
def preprocess_spectrum(spectrum):
    # é¢„å¤„ç†é€»è¾‘
    return processed_spectrum
```

### 10.3 æ¨¡åž‹ä¼˜åŒ–

```python
# æ¨¡åž‹é‡åŒ–
import torch.quantization

model_int8 = torch.quantization.quantize_dynamic(
    model, {torch.nn.Linear}, dtype=torch.qint8
)

# æ¨¡åž‹å‰ªæž
from torch.nn.utils import prune

for module in model.modules():
    if isinstance(module, torch.nn.Linear):
        prune.l1_unstructured(module, name='weight', amount=0.2)

# ONNXå¯¼å‡ºï¼ˆåŠ é€ŸæŽ¨ç†ï¼‰
torch.onnx.export(
    model,
    dummy_input,
    "model.onnx",
    opset_version=14,
    input_names=['input'],
    output_names=['output']
)
```

---

## 1ï¸âƒ£1ï¸âƒ£ æˆæœ¬è¯„ä¼°

### 11.1 ç¡¬ä»¶æˆæœ¬ï¼ˆå·²æœ‰ï¼‰

| ç»„ä»¶ | ä»·å€¼ | çŠ¶æ€ |
|------|------|------|
| RTX 4060 Ti 16GB | Â¥3,500 | âœ… å·²æœ‰ |
| i7-12700K + ä¸»æ¿ | Â¥5,000 | âœ… å·²æœ‰ |
| 62GB RAM | Â¥1,500 | âœ… å·²æœ‰ |
| SSD 147GB | Â¥500 | âœ… å·²æœ‰ |
| **æ€»è®¡** | **Â¥10,500** | **å·²æœ‰ç¡¬ä»¶** |

### 11.2 è½¯ä»¶æˆæœ¬

| é¡¹ç›® | æˆæœ¬ | å¤‡æ³¨ |
|------|------|------|
| PyRamEx | Â¥0 | å¼€æº |
| Docker | Â¥0 | å…è´¹ç‰ˆ |
| Ollamaæ¨¡åž‹ | Â¥0 | å¼€æºæ¨¡åž‹ |
| PostgreSQL | Â¥0 | å¼€æº |
| Redis | Â¥0 | å¼€æº |
| **å¹´åº¦æ€»æˆæœ¬** | **Â¥0** | **å…¨éƒ¨å¼€æº** |

### 11.3 è¿ç»´æˆæœ¬

| é¡¹ç›® | æœˆåº¦æˆæœ¬ | å¹´åº¦æˆæœ¬ |
|------|----------|----------|
| ç”µåŠ›ï¼ˆ165W GPUï¼‰ | Â¥50 | Â¥600 |
| å­˜å‚¨ï¼ˆå¦‚éœ€æ‰©å±•ï¼‰ | Â¥0-100 | Â¥0-1,200 |
| å¤‡ä»½äº‘å­˜å‚¨ï¼ˆå¯é€‰ï¼‰ | Â¥0-50 | Â¥0-600 |
| **æ€»è®¡** | **Â¥50-200** | **Â¥600-2,400** |

### 11.4 æˆæœ¬å¯¹æ¯”

| æ–¹æ¡ˆ | åˆæœŸæˆæœ¬ | å¹´åº¦è¿ç»´ | 3å¹´æ€»æˆæœ¬ |
|------|----------|----------|-----------|
| **æœ¬æ–¹æ¡ˆï¼ˆGPU+Dockerï¼‰** | Â¥0 | Â¥600 | Â¥600 |
| äº‘GPUæœåŠ¡å™¨ | Â¥0 | Â¥10,000 | Â¥30,000 |
| ä¼ ç»ŸCPUæ–¹æ¡ˆ | Â¥0 | Â¥100 | Â¥300 |

**èŠ‚çœï¼š** 3å¹´èŠ‚çœ **Â¥29,400** ç›¸æ¯”äº‘GPUæ–¹æ¡ˆ

---

## 1ï¸âƒ£2ï¸âƒ£ é£Žé™©ä¸Žç¼“è§£

### 12.1 æŠ€æœ¯é£Žé™©

| é£Žé™© | å½±å“ | æ¦‚çŽ‡ | ç¼“è§£æŽªæ–½ |
|------|------|------|----------|
| GPUå†…å­˜ä¸è¶³ | ä¸­ | ä¸­ | åŠ¨æ€batchã€æ¨¡åž‹é‡åŒ– |
| Dockerå…¼å®¹æ€§é—®é¢˜ | ä½Ž | ä½Ž | å……åˆ†æµ‹è¯•ã€ç‰ˆæœ¬é”å®š |
| Ollamaæ¨¡åž‹è´¨é‡ | ä¸­ | ä¸­ | Promptå·¥ç¨‹ã€æ¨¡åž‹å¾®è°ƒ |
| CUDAç‰ˆæœ¬å†²çª | ä½Ž | ä½Ž | ä½¿ç”¨Dockerç»Ÿä¸€çŽ¯å¢ƒ |

### 12.2 è¿è¥é£Žé™©

| é£Žé™© | å½±å“ | æ¦‚çŽ‡ | ç¼“è§£æŽªæ–½ |
|------|------|------|----------|
| æ•°æ®ä¸¢å¤± | é«˜ | ä½Ž | è‡ªåŠ¨å¤‡ä»½ã€RAID |
| æœåŠ¡ä¸­æ–­ | ä¸­ | ä¸­ | å¥åº·æ£€æŸ¥ã€è‡ªåŠ¨é‡å¯ |
| å®‰å…¨æ¼æ´ž | é«˜ | ä½Ž | å®šæœŸæ›´æ–°ã€æ¼æ´žæ‰«æ |
| æ€§èƒ½ä¸‹é™ | ä¸­ | ä¸­ | ç›‘æŽ§ã€ä¼˜åŒ– |

### 12.3 ä¸šåŠ¡é£Žé™©

| é£Žé™© | å½±å“ | æ¦‚çŽ‡ | ç¼“è§£æŽªæ–½ |
|------|------|------|----------|
| ç”¨æˆ·éœ€æ±‚å˜åŒ– | ä¸­ | ä¸­ | æ¨¡å—åŒ–è®¾è®¡ã€å¿«é€Ÿè¿­ä»£ |
| æŠ€æœ¯æ ˆè¿‡æ—¶ | ä½Ž | ä½Ž | æŒç»­å­¦ä¹ ã€æž¶æž„å‡çº§ |
| äººæ‰æµå¤± | ä¸­ | ä½Ž | æ–‡æ¡£å®Œå–„ã€çŸ¥è¯†å…±äº« |

---

## âœ… æ€»ç»“

### æ ¸å¿ƒä¼˜åŠ¿

âœ… **é«˜æ€§èƒ½** - GPUåŠ é€Ÿï¼Œ10-50xæ€§èƒ½æå‡  
âœ… **æ™ºèƒ½åŒ–** - Ollamaæœ¬åœ°LLMï¼ŒAIè¾…åŠ©åˆ†æž  
âœ… **æ ‡å‡†åŒ–** - Dockerå®¹å™¨åŒ–ï¼Œæ˜“äºŽéƒ¨ç½²å’Œè¿ç§»  
âœ… **ä½Žæˆæœ¬** - å…¨å¼€æºæ–¹æ¡ˆï¼Œé›¶è½¯ä»¶æˆæœ¬  
âœ… **å¯æ‰©å±•** - å¾®æœåŠ¡æž¶æž„ï¼Œæ˜“äºŽæ‰©å±•  
âœ… **ç”Ÿäº§çº§** - å®Œæ•´ç›‘æŽ§ã€å¤‡ä»½ã€å®‰å…¨æœºåˆ¶  

### æŠ€æœ¯äº®ç‚¹

ðŸŽ¯ **GPUåŠ é€Ÿ** - å……åˆ†åˆ©ç”¨RTX 4060 Ti 16GB  
ðŸ¤– **AIåŽŸç”Ÿ** - Ollamaæœ¬åœ°LLMæ™ºèƒ½åˆ†æž  
ðŸ³ **å®¹å™¨åŒ–** - Dockeræ ‡å‡†åŒ–éƒ¨ç½²  
âš¡ **é«˜æ€§èƒ½** - RAPIDS cuMLåŠ é€ŸMLè®¡ç®—  
ðŸ”’ **å®‰å…¨å¯é ** - å®Œæ•´çš„å®‰å…¨å’Œå¤‡ä»½æœºåˆ¶  

### é¢„æœŸæˆæžœ

- ðŸ“Š **æ€§èƒ½æå‡**ï¼šç›¸æ¯”CPUæ–¹æ¡ˆï¼Œè®¡ç®—é€Ÿåº¦æå‡10-50å€
- ðŸ¤– **æ™ºèƒ½åŒ–**ï¼šAIè‡ªåŠ¨ç”Ÿæˆåˆ†æžæŠ¥å‘Šï¼Œæ•ˆçŽ‡æå‡100å€
- ðŸš€ **å¯æ‰©å±•**ï¼šæ˜“äºŽè¿ç§»åˆ°äº‘ç«¯æˆ–æ‰©å±•åˆ°å¤šèŠ‚ç‚¹
- ðŸ’° **æˆæœ¬èŠ‚çº¦**ï¼šç›¸æ¯”äº‘GPUæ–¹æ¡ˆï¼Œ3å¹´èŠ‚çœçº¦Â¥30,000

---

**æ–‡æ¡£ç»´æŠ¤è€…ï¼š** å°é¾™è™¾1å· ðŸ¦ž  
**æœ€åŽæ›´æ–°ï¼š** 2026-02-15  
**ä¸‹æ¬¡å®¡æŸ¥ï¼š** 2026-05-15  

**çŠ¶æ€ï¼š** âœ… é¡¹ç›®æ–¹æ¡ˆå®Œæˆï¼Œå‡†å¤‡æ‰§è¡Œ

---

## ðŸ“ž è”ç³»æ–¹å¼

- **é¡¹ç›®è´Ÿè´£äººï¼š** å°é¾™è™¾1å· ðŸ¦ž
- **æŠ€æœ¯æ”¯æŒï¼š** https://github.com/openclaw/pyramex/issues
- **æ–‡æ¡£ä½ç½®ï¼š** `/home/yongming/openclaw/pyramex/docs/`

---

*Let's build the future of Raman spectroscopy analysis together!* ðŸš€
