{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyRamEx Tutorial: ML/DL-Friendly Raman Spectroscopy Analysis\n",
    "\n",
    "This notebook demonstrates how to use PyRamEx for Raman spectroscopic data analysis with machine learning and deep learning integration.\n",
    "\n",
    "## Installation\n",
    "\n",
    "```bash\n",
    "pip install pyramex\n",
    "```\n",
    "\n",
    "## Quick Start\n",
    "\n",
    "Load data, preprocess, and apply ML models in just a few lines!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PyRamEx\n",
    "from pyramex import Ramanome, load_spectra\n",
    "import numpy as np\n",
    "\n",
    "# Load data\n",
    "data = load_spectra('path/to/spectra/')\n",
    "print(f\"Loaded {data.n_samples} spectra with {data.n_wavenumbers} wavenumber points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading\n",
    "\n",
    "PyRamEx supports multiple Raman spectroscopy file formats from major manufacturers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Load single file\n",
    "data = load_spectra('single_spectrum.txt')\n",
    "\n",
    "# Option 2: Load directory with multiple files\n",
    "data = load_spectra('spectra_directory/')\n",
    "\n",
    "# Option 3: Create from NumPy arrays\n",
    "spectra = np.random.randn(100, 1000)  # 100 samples, 1000 points\n",
    "wavenumbers = np.linspace(200, 4000, 1000)\n",
    "metadata = {'sample_id': [f'S{i}' for i in range(100)]}\n",
    "data = Ramanome(spectra, wavenumbers, metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing\n",
    "\n",
    "Apply common preprocessing steps with method chaining:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess with method chaining\n",
    "data_processed = data.smooth(window_size=5, polyorder=2) \\\n",
    "    .remove_baseline(method='polyfit', degree=3) \\\n",
    "    .normalize(method='minmax') \\\n",
    "    .cutoff(wavenumber_range=(500, 3500))\n",
    "\n",
    "print(f\"Applied {len(data_processed.processed)} preprocessing steps\")\n",
    "print(data_processed.processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Quality Control\n",
    "\n",
    "Remove low-quality samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply quality control\n",
    "qc_result = data_processed.quality_control(method='icod', threshold=0.05)\n",
    "print(qc_result)\n",
    "\n",
    "# Filter bad samples\n",
    "data_clean = data_processed[qc_result.good_samples]\n",
    "print(f\"Retained {data_clean.n_samples}/{data_processed.n_samples} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Dimensionality Reduction\n",
    "\n",
    "Reduce dimensions for visualization and feature extraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA\n",
    "data_clean.reduce(method='pca', n_components=2)\n",
    "\n",
    "# Plot reduction\n",
    "data_clean.plot_reduction(method='pca', color_by='label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Machine Learning Integration\n",
    "\n",
    "### 5.1 Scikit-Learn Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Convert to sklearn format\n",
    "X_train, X_test, y_train, y_test = data_clean.to_sklearn_format(test_size=0.2)\n",
    "\n",
    "# Train model\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 PyTorch Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Create PyTorch dataset\n",
    "dataset = data_clean.to_torch_dataset()\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Create CNN model\n",
    "model = create_cnn_model(\n",
    "    input_length=data_clean.n_wavenumbers,\n",
    "    n_classes=len(np.unique(y_train)),\n",
    "    dropout=0.3\n",
    ")\n",
    "\n",
    "# Training loop (simplified)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(10):\n",
    "    for batch_x, batch_y in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 TensorFlow Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Create TensorFlow dataset\n",
    "dataset = data_clean.to_tf_dataset(batch_size=32, shuffle=True)\n",
    "\n",
    "# Build simple model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv1D(32, 5, activation='relu', input_shape=(1, data_clean.n_wavenumbers)),\n",
    "    tf.keras.layers.MaxPooling1D(2),\n",
    "    tf.keras.layers.Conv1D(64, 5, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling1D(2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(len(np.unique(y_train)), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train\n",
    "model.fit(dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Engineering\n",
    "\n",
    "Extract specific spectral features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyramex.features import extract_band_intensity, calculate_cdr\n",
    "\n",
    "# Extract band intensities\n",
    "bands = [(2000, 2250), (2750, 3050), 1450, 1665]\n",
    "features = extract_band_intensity(data_clean, bands)\n",
    "print(f\"Extracted {features.shape[1]} band features\")\n",
    "\n",
    "# Calculate CDR ratio\n",
    "cdr = calculate_cdr(data_clean, band1=(2000, 2250), band2=(2750, 3050))\n",
    "print(f\"CDR range: {cdr.min():.3f} to {cdr.max():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualization\n",
    "\n",
    "Interactive and static visualizations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot spectra\n",
    "data_clean.plot(n_samples=10)\n",
    "\n",
    "# Plot preprocessing effects\n",
    "data_clean.plot_preprocessing_steps()\n",
    "\n",
    "# Plot quality control results\n",
    "data_clean.plot_quality_control(method='icod')\n",
    "\n",
    "# Interactive plot (requires plotly)\n",
    "data_clean.interactive_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Complete Workflow Example\n",
    "\n",
    "End-to-end pipeline from raw data to trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load data\n",
    "data = load_spectra('path/to/data/')\n",
    "\n",
    "# 2. Preprocess\n",
    "data = data.smooth().remove_baseline().normalize()\n",
    "\n",
    "# 3. Quality control\n",
    "qc = data.quality_control(method='icod')\n",
    "data = data[qc.good_samples]\n",
    "\n",
    "# 4. Dimensionality reduction (optional)\n",
    "data.reduce(method='pca', n_components=50)\n",
    "\n",
    "# 5. Convert to ML format\n",
    "X_train, X_test, y_train, y_test = data.to_sklearn_format()\n",
    "\n",
    "# 6. Train model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 7. Evaluate\n",
    "print(f\"Test accuracy: {model.score(X_test, y_test):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "PyRamEx provides:\n",
    "- ✅ Easy data loading from multiple formats\n",
    "- ✅ Method chaining for preprocessing\n",
    "- ✅ Multiple QC methods\n",
    "- ✅ Seamless ML/DL integration\n",
    "- ✅ Interactive visualizations\n",
    "- ✅ GPU acceleration support (optional)\n",
    "\n",
    "For more information, see:\n",
    "- GitHub: https://github.com/openclaw/pyramex\n",
    "- Original RamEx: https://github.com/qibebt-bioinfo/RamEx"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
